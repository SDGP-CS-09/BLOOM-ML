{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099cacd2-0ce4-4164-944b-1684b8df5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6f59fc-451c-4ede-9df7-371c14186cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "BATCH_SIZE=32\n",
    "CHANNELS=3\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dce12e-6a1c-44be-ad76-2d044f9a44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image Function\n",
    "def load_image_with_error_handling(filepath):\n",
    "    try:\n",
    "        img = tf.io.read_file(filepath)\n",
    "        img = tf.image.decode_image(img, channels=3)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f7f183-fb40-4739-a3c8-d2498b983a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24844 files belonging to 10 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DatasetV2.ignore_errors() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Datasets with Error Handling\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      6\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m )\u001b[38;5;241m.\u001b[39mapply(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mignore_errors())\n\u001b[0;32m      9\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     13\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m )\u001b[38;5;241m.\u001b[39mapply(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mignore_errors())\n",
      "\u001b[1;31mTypeError\u001b[0m: DatasetV2.ignore_errors() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# Load Datasets with Error Handling\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"train\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\"\n",
    ").apply(tf.data.Dataset.ignore_errors())\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"val\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\"\n",
    ").apply(tf.data.Dataset.ignore_errors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3c669-277d-439f-8461-811771f9a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Caching\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c33b4-c362-4aa7-b0e8-b938e77f4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0 / 255)\n",
    "])\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6a69a-bc19-4c9d-922c-145ab30d9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_ignore_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f35b2-6099-44e1-a706-b94a4f4491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 10\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddf474-1ac6-40b7-bba4-05af82c093e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8a596-a71b-436b-a1d1-8ad3a13bc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3f69f-193a-4a01-a5e1-0500fdf672ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b94d4-8814-4e0b-8900-0f61d14b085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch,label_batch in dataset.take(1):\n",
    "    print(image_batch.shape)\n",
    "    print(label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a034b-4bbe-48c7-a88e-a60ae2b760f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image_batch,label_batch in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        ax=plt.subplot(3,4,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[label_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c9158-0ad3-4c83-9b1b-b22aae4fd4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a0a8d-617c-4218-b036-6b9bd6b5b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f3412-5241-49a4-94fe-41273eaf5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=dataset.take(54)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e863e-00c0-437d-b94f-5af1fab2aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=dataset.skip(54)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774995f4-b0a3-407d-8267-a8f78fdebd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size=0.1\n",
    "len(dataset)*val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ceab36-d616-47c2-a27a-c5151afabc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds=test_ds.take(6)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6587b1-f26a-49e0-871e-4e776bd0cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=test_ds.skip(6)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1950f-6843-4495-a7e8-c0861a86694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partition_tf(ds,train_split=0.8,val_split=0.1,test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    ds_size=len(ds)\n",
    "    if shuffle:\n",
    "        ds=ds.shuffle(shuffle_size,seed=12)\n",
    "\n",
    "    train_size=int(train_split*ds_size)\n",
    "    val_size=int(val_split*ds_size)\n",
    "\n",
    "    train_ds=ds.take(train_size)\n",
    "\n",
    "    val_ds=ds.skip(train_size).take(val_size)\n",
    "    test_ds=ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    \n",
    "    return train_ds,val_ds,test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3cd8ee-4001-43bc-a4a0-06b9ab24469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds,test_ds=get_dataset_partition_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ebf96-842d-45d2-b14d-008c9661d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83661e91-bd29-4ed5-8bc0-27a81798504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69d7ab-b04d-429c-800b-80948bab5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cc3ed-aa00-4097-a519-fcedd1bfe174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a68ff-e806-4244-94b5-2496404c2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale =tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f145d-9cbd-4d34-b6e8-bae3f0863999",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation=tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_andvertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f53c2-90cf-4835-b782-4e82f4bcc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,CHANNELS)\n",
    "n_classes=3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)),\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc5584-a3b4-4938-b66d-bed570ee10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a323f-b2d7-4500-a80b-e1020c20da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe64cb-6c0d-462d-8449-b50b2e248c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8845a-2129-4f9d-98bf-01917226dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a6a94-4094-44eb-992d-0c96d7e43c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4ed99-5e43-464c-abdf-e60086deec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195819f1-a8e3-45e0-9d56-bb0aa036c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3059e-865c-43f6-9741-0b1a4edbe76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c794f-de90-4951-b1cf-d2ec9ac1ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293a2bc-c09e-4c3e-88c1-4eb4d2d5d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74436647-b2fe-4cac-be06-26869792f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(8,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS),acc, label = 'Training Accuracy')\n",
    "plt.plot(range(EPOCHS),val_acc, label = 'Validation Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(EPOCHS), loss, label = 'Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dde749-1f3d-4f69-b7be-6f12c6e15dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "\n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "\n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"predicted label:\", class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5978a5d-ea80-43c7-913f-84d26778650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903e909-c266-45e5-8acc-5deb0a2e6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]]\n",
    "\n",
    "        plt.title(f\"Actual: {actual_class}\\n Predicted: {predicted_class}.\\n confidence: {confidence}%\")\n",
    "\n",
    "\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efb273-b62b-43aa-9fec-b68aef65bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a0c9a-1477-421a-88e1-317cc6965c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variable bellpepper_dep\n",
    "bellpepper_dep = \"v1.0\"  # You can set this to the appropriate version string\n",
    "\n",
    "# Now you can use it to save the model\n",
    "model_version = bellpepper_dep\n",
    "model.save(f\"model/{model_version}.keras\")  # Save the model with the version in the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d235c61-8f60-4859-bf34-0c0ea6637669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('bellpepper_model.h5')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f6901-7d8d-4b7e-a8b6-e5dfc17c9b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
